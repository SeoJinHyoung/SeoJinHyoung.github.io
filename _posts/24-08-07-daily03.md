---
layout: single
title: "AI tech 세번째 날!"
---
# 세번째 날!

제가 뭐하고 있는지도 안 말하고 첫번째, 두번째 날 했네요...ㅎ

저는 네이버 커넥트에서 진행하는 Boost course를 듣고 있고 CV트랙을 듣고 있습니다.

지금은 PyTorch 문법 열심히 배우고 있습니다.

오늘까지 해야되는 과제를 다 못해서 개운치는 않네요

그래도 팀원들 앞에서 논문발표 하나 했습니다.

[한글 텍스트 감정 이진 분류 모델 생성을 위한 미세 조정과 전이학습에 관한 연구](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=JAKO202331440016936)

위 논문인데 평소의 논문을 잘 읽을 일이 없기도 하고 AI 관련 지식이 부족하다 보니 읽기만 해도 벅찼는데 

발표자료까지 준비하니 힘들긴 했습니다만

차차 익숙해지면 트렌드도 잘 읽을 수 있지 않을까 생각합니다.


제가 했던 발표를 다시 보여드리고자 합니다.

# 이진분류 논문 리뷰
![image](../Binary-Classification-thesis-review/슬라이드1.PNG)
제가 발표할 주제는 이진분류였는데 저희는 CV트랙에 해당했지만 주제가 흥미로워보여 본 논문을 리뷰하기로 결정했습니다.

![image](../Binary-Classification-thesis-review/슬라이드2.PNG)
우선 본 논문을 요약하자면 생성형 모델이 크게 유행하고 본 저자도 다국어 번역기 모델을 이용하여 한글 문장을 긍정 또는 부정으로 분류하는 모델로 미세조정 및 전이학습을 진행하였습니다.

![image](../Binary-Classification-thesis-review/슬라이드3.PNG)
그전에 앞서 각 모델마다 성능 분석을 하는 연구를 진행하였습니다.

![image](../Binary-Classification-thesis-review/슬라이드4.PNG)
본 그래프는 Colab 기본 모델의 정확도와 손실 그래프입니다.
그래프에서, 학습데이터의 정확도와 손실은 학습 횟수를 거듭할수록 향상되지만, 테스트 데이터셋을 이용한 검증에서는, 대략 15회 학습 전 후로는 크게 성능향상을 보이지 않는다는 것을 확인할 수 있습니다.
여기에서 F1 Score는 데이터 불균형 문제에서 사용되는 평가 지표입니다.
예를 들자면 10개의 ox 문제에서 정답이 9개가 o인데 모델이 전부 o라고 구분했다면 정확도는 0.9이지만 좋은 모델이라고 보기 어렵습니다.
그렇기에 F1 Score는 클래스의 비중을 반영한 지표라고 볼 수 있습니다.

![image](../Binary-Classification-thesis-review/슬라이드5.PNG)
일반 RNN모델은 단방향으로 진행되어 문장 끝을 사용하지 못합니다.
그러나 일반 RNN 모델과 달리 양방향 RNN모델은 독립된 RNN이 양방향으로 입력을 받고 양방향으로 출력을 합니다.
다시 말하자면 문장을 정방향으로 입력받는 정방향 RNN과 역방향 RNN이 입력을 받아 출력을 결합합니다.
고로 문장의 끝부분까지도 사용가능하지만 이전 모델과 비교해 정확도, 손실, F1점수등 크게 좋아지지는 않았습니다.

![image](../Binary-Classification-thesis-review/슬라이드6.PNG)
BERT는 트랜스포머 아키텍처를 기반으로 합니다. 트랜스포머는 주목(attention) 메커니즘을 사용하여 입력 시퀀스의 모든 요소 간의 관계를 학습합니다.
AdamW 최적화 기법을 사용하고 정확도, 손실, F1 점수 모두 이전 모델들 보다 좋은 결과를 내놓았습니다.
이처럼 BERT 모델이 텍스트 분류에는 적합하고 높은 성능을 보여줌, 고로 논문작성자는 해당 모델을 바탕으로 연구를 진행하였습니다.

![image](../Binary-Classification-thesis-review/슬라이드7.PNG)
해당 논문의 저자는 사전학습된 번역기용 BERT-Base 모델을 미세조정하여  한글문장의 감정 이진 분류를 위한 모델로 구현하였습니다.
위 이미지는 입력에서 기존 모델에서 어떤 부분을 수정하였는지 보여주는 레이어 이미지 입니다.
입력에서의 미세조정은 서브워드 토큰 임베딩과 세그먼트 임베딩을 추가하였고 출력에서는 문장이 긍정인지 부정인지 구분하는 Dense 레이어를 추가하였습니다.
서브워드 토큰 임베딩은 input된 문장을 BERTEncoding(벡터)으로 변환후 학습을 진행하는 레이어,
세그먼트 임베딩은 해당 문장이 앞에서 나오는지 뒤에서 나오는지 알려준 후 학습을 진행하는 레이어입니다.

![image](../Binary-Classification-thesis-review/슬라이드8.PNG)
출력 부분 레이어 이미지입니다.
앞서 말했듯 번역기 모델을 이용한 것이기 때문에 필요 없는 레이어는 전부 제거하였습니다.
출력부분에서 점선으로 표시된 레이어를 제거하고 초록 점선으로 표시되어 있는 레이어를 추가한 것 입니다.
해당 레이어는 문장을 긍정, 부정으로 구분하는 Dense 레이어입니다.

![image](../Binary-Classification-thesis-review/슬라이드9.PNG)
문장이 input으로 들어오게 되면 Tokenizer가 문장을 쪼개고 토큰을 생성합니다.
예를들면 “전이학습을 통한 텍스트 감정분류”, “사전 학습된 버트 파인튜닝” 이라고 입력이 들어오면 BERTTokenizer 가 문장을 쪼개고 [CLS]와 [SEP] 토큰으로 문장 시작과 끝을 구분합니다.

![image](../Binary-Classification-thesis-review/슬라이드10.PNG)
한글 학습데이터셋 10,000개, 테스트데이터셋 5,000개로 학습된 모델에 대해, 테스트 데이터 셋을 사용하여 확인한 결과, F1 점수 0.81과 정 확도 0.81이 일치함으로써, 모델 학습이 어느 한 쪽에 치우치지 않고 성공적으로 수행되었음을 알 수 있습니다.
미세조정된 모델의 과적합 여부를 판단하기 위해 데이터 셋을 2~5배 증가시켜서 모델을 생성하였고 RNN모델보다 BERT구조의 모델이 성능이 뛰어나고 데이터셋의 크기를 높일수록 F1점수가 선형적으로 높아지는 것을 확인 할 수 있습니다.

![image](../Binary-Classification-thesis-review/슬라이드11.PNG)
추가로 모델의 성능과 데이터셋의 상관을 분석하기 위해 Table 5와 같이 학습데이터 크기25,252, 테스트데이터 크기 7,222인 신문기사 댓글 데이터셋을 사용하여 모델을 학습시킨 후, 성능을 분석하였습니다.
근데 자세히 보면 데이터 라벨링이 문장레벨에서만 볼 때 만 긍정적이고 전체 문맥상으로 보면 비꼬는 듯한 부정적인 뉘앙스인 것 같았습니다.
제 생각에는 이러한 데이터를 바탕으로 학습이 진행되었다면 비꼬는 듯한 문장 등의 부정적인 문장은 구별하기 힘들지 않을까 의문이 들었습니다...

어찌되었든 신문기사 댓글을 학습데이터 10,000건, 테스트 데이터셋의 크기로 5,000건으로 조정한 후, 5회 학습시킨 결과, 정확도 0.9656, 손실 0.0929, 부정에 대한 F1 점수 0.95, 긍정에대한 F1점수 0.31의 성능을 보이는 모델을 얻었다. 결과에서 긍정과 부정에 대한 F1 점수가 차이가 나는 것은 신문기사 댓글 데이터셋 자체에 부정 댓글이 많은 이유입니다.

![image](../Binary-Classification-thesis-review/슬라이드12.PNG)
주성분분석(principal component analysis)과 TSNE(t-distributed stochastic neighbor embedding) 클러스터링 알고리즘을 사용하면, 테스트 데이터셋으로 예측된 결과의 분포를 3차 원 그래프로 시각화할 수 있습니다. 
주성분분석(principal component analysis): 전체 데이터 분포를 서로 직교하는(orthogonal) 선형 벡터(linear vector)의 합으로 표현
TSNE(t-distributed stochastic neighbor embedding) 클러스터링: 차원을 축소하여, 유사한 것끼리 클러스터를 생성하는 알고리즘

![image](../Binary-Classification-thesis-review/슬라이드13.PNG)
결론은 LLM 분야에서 많은 AI 연구가 이루어져있고 본 논문의 연구 내용에 따르면 BERT 기반 모델이 성능이 가장 우수하며 소개된 방법으로 한국어 바탕 모델을 신속하게 테스트 가능하다고 합니다.
나중에 논문에서 소개된 모델을 그대로 쓸 것 같지는 않지만 논문에 소개된 방법으로 나만의 모델을 만드는 데에는 도움이 될것 같습니다.


