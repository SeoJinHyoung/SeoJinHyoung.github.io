---
layout: single
title: "AI tech 다섯번째 날!"
---
# 다섯번째 날!

오늘은 과제를 오전 중에 제출해야 되서 점심도 미루고 허둥지둥 하였습니다.

강좌 수강이나 퀴즈도 무난하게 진행하였으나 과제 중에서 하나가 제 발목을 잡더군요.

아래 코드는 로지스틱 회귀 모델의 학습 코드 중 일부입니다.

<pre>
  <code>
    def train(model, criterion, optimizer, dataloader, device, num_epoch=100):
    model.train()
    model.to(device)

    for epoch in range(num_epoch):
        epoch_loss = 0.0
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        print(f"Epoch {epoch+1}, Loss: {epoch_loss}")
  </code>
</pre>

제가 초기에 작성한 코드입니다.
저 코드대로 작성을 하고 train을 진행하니 오류가 따다닷 뜨더라고요.

<pre>
  <code>
    RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)
  </code>
</pre>
아, 데이터가 GPU로 넘어가지 않았구나
하고 넘겨주었습니다.

<pre>
  <code>
    inputs = inputs.to(device)
    targets = targets.to(device)
  </code>
</pre>
그리고 실행...

<pre>
  <code>
    RuntimeError: mat1 and mat2 must have the same dtype, but got Double and Float
  </code>
</pre>
다시 오류
아, feature데이터와 target데이터가 형이 안맞는구나
하고 수정해줬습니다.

<pre>
  <code>
    inputs = inputs.to(device).float()
    targets = targets.to(device).float()
  </code>
</pre>

이러고 또 오류가 났었습니다.
살짝 열받는게 아까는 오류떴었는데 지금은 같은 코드임에도 실행이 되네요...

그래서 다른 캠퍼분과 조교분들께 질문을 드리고 열심히 구글링한 결과...!

GPU는 병렬 연산 목적으로 만들어져 있어 데이터 타입 변환에 대해서는 약할 수 있다는 것을 알았습니다...
고로 device에 데이터를 넘기기전에 CPU 내에서 형변환을 먼저 실행하면 되더군요.

<pre>
  <code>
            inputs = inputs.float().to(device)
            targets = targets.float().to(device)
  </code>
</pre>

코드는 위와 같습니다.

저렇게 순서만 바꾼다고 정상작동한다니...

뿌듯하면서 허무하네요


